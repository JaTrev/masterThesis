{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"evaluation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPf7yvoHpwP0IqGoPr/aVZ7"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"jQXflsqcP0Hc","colab_type":"code","colab":{}},"source":["from itertools import combinations \n","from collections import Counter\n","from sklearn import metrics\n","import numpy as np\n","import gensim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hhPbHwv1P8yV","colab_type":"code","colab":{}},"source":["top_n_topic_words = 9\n","\n","def getWordCount(docs:list):\n","  \"\"\"\n","  Return a count of all words in the documents.\n","  \"\"\"\n","\n","  temp = []\n","  for doc in docs:\n","    temp.extend(doc)\n","\n","  return Counter(temp)\n","\n","\n","\n","def getClusterWords(docs_cleaned:list, words:list, n_concept:int, \n","                    vocab_dict:dict, word_labels=None, \n","                    doc_labels=None): -> list\n","  \"\"\"\n","  Function returns a list of words for each cluster.\n","  \"\"\"\n","  \n","  labels = None\n","  if isinstance(word_labels, list):\n","    labels = word_labels\n","  elif isinstance(doc_labels, list):\n","    labels = doc_labels\n","  else:\n","    print(\"Need to add word_labels or doc_labels\")\n","    return\n","\n","  \n","  word_counts = getWordCount(docs_cleaned)\n","  vocab =  list(vocab_dict.values())\n","  corpus = [vocab_dict.doc2bow(text) for text in docs_cleaned]\n","  tfidf = gensim.models.TfidfModel(corpus, id2word=vocab_dict.id2token)\n","  corpus_tfidf = tfidf[corpus]\n","\n","\n","  # group all words in the vocab by clusters\n","  cluster_words = [[] for i in range(n_concept)]\n","\n","  if isinstance(doc_labels, list) :\n","    # working on document level\n","    for doc_id, doc in enumerate(docs_cleaned):\n","      cluster_words[doc_labels[doc_id]].extend([w for w in doc \n","                                                if w in vocab])\n","  else:\n","    # working on word level\n","    for word_id, word in enumerate(words):\n","      if word in vocab:\n","        # make sure the word is in the vocabulary\n","        cluster_words[word_labels[word_id]].append(word)\n","\n","\n","  # calculate absolute frequency * idf for cluster_words:\n","  cluster_words_freq = [[] for i in range(n_concept)]\n","  for cluster_id, cluster_list in enumerate(cluster_words):\n","\n","    # remove any duplicates\n","    cluster_list = list(set(cluster_list))\n","\n","    for w in cluster_list:\n","\n","      # weight words by their absolute frequency and their idf\n","      w_absolute_count = word_counts.get(w)\n","      w_idf = corpus_tfidf.obj.idfs[dictionary.token2id[w]]\n","      cluster_words_freq[cluster_id].append([w, w_absolute_count * w_idf])\n","\n","\n","  \"\"\"\n","  # assign absolute frequence to each word of each cluster\n","  cluster_words_freq = [[] for i in range(n_concept)]\n","  for cluster_id, cluster_list in enumerate(cluster_words):\n","\n","    for w in cluster_list:\n","\n","      w_count = word_counts.get(w)\n","      cluster_words_freq[cluster_id].append([w, w_count])\n","  \"\"\"\n","\n","\n","  # sort each word by their absolute frequency\n","  cluster_words_sorted = [[] for i in range(n_concept)]\n","  for cluster_id, cluster_list in enumerate(cluster_words_freq):\n","    \n","\n","    sorted_list = sorted(cluster_list, key= lambda x: x[1], reverse=True)\n","    cluster_words_sorted[cluster_id].extend(list(set(map(\n","        itemgetter(0), sorted_list ))))\n","  \n","  return cluster_words_sorted\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FGYLnxFVALHk","colab_type":"code","colab":{}},"source":["from sklearn.metrics.pairwise import cosine_similarity\n","from math import log2, log10, log1p\n","import numpy as np\n","\n","def coherenceScore(cluster_words_sorted:list, \n","                   w2v_model=None, top_n_topic_words=10,\n","                   n_clusters=20):\n","  \"\"\"\n","  Calculating the coherence score using word embeddings and \n","  cosine similarity.\n","\n","  \"\"\"\n","  assert n_clusters == len(cluster_words_sorted), (\"len(cluster_words_sorted) \"\n","                                                    \"!= n_clusters\")\n","  per_topic_cs = [0 for _ in range(n_clusters)]\n","  for topic_id, topic_word_list in enumerate(cluster_words_sorted):\n","\n","    top_words = topic_word_list[:top_n_topic_words]\n","\n","    # calculate similarity for each pair of terms\n","    pair_scores = 0\n","    for pair in combinations(top_words, 2):\n","\n","      pair_scores += log1p(cosine_similarity(\n","          w2v_model.wv.get_vector(pair[0]).reshape(1, -1), \n","          w2v_model.wv.get_vector(pair[1]).reshape(1, -1)))\n","    \n","\n","    # devide the score by the number of pairs\n","    per_topic_cs[topic_id] =  pair_scores / sum(range(top_n_topic_words)) \n","\n","\n","  # return the mean score across all topics \n","  return np.average(per_topic_cs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MoJIbAC6jXie","colab_type":"code","colab":{}},"source":["from s_dbw import S_Dbw\n","def s_Dbw_validity_index(data, labels_pred, centers_id):\n","  \n","  return S_Dbw(data, labels_pred, centers_id, method='Halkidi', \n","               alg_noise='bind', centr='mean',nearest_centr=True, \n","               metric='euclidean')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3K4Y4rP6jXmG","colab_type":"code","colab":{}},"source":["def silhoutteCoefficient(data, labels_pred):\n","  return metrics.silhouette_score(data, labels_pred)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2rbrotpZjO2i","colab_type":"code","colab":{}},"source":["def internalValidation(data, labels_pred, centers_id):\n","  \"\"\"\n","  return the Silhoutte Coefficient and the s_Dbw index as a tuple\n","  \"\"\"\n","  s_coefficient = silhoutteCoefficient(data, labels_pred)\n","  s_Dbw = s_Dbw_validity_index(data, labels_pred, centers_id)\n","  return s_coefficient, s_Dbw\n","  \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p2Agr_wKjeZI","colab_type":"code","colab":{}},"source":["def adjustedRandIndex(labels_true, labels_pred):\n","  \"ARI used to examine homogeinity and competeness\"\n","  return metrics.adjusted_rand_score(labels_true, labels_pred)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sNCOzH50jlIT","colab_type":"code","colab":{}},"source":["def fowlkesMallowsIndex(labels_true, labels_pred):\n","  \"FMI used to examine recall and precision\"\n","  return metrics.fowlkes_mallows_score(labels_true, labels_pred)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5oVgPRvGj7JC","colab_type":"code","colab":{}},"source":["def externalValidation(labels_true, labels_pred):\n","  \"\"\"\n","  return the results of all external evaluations\n","  \"\"\"\n","  fmi = fowlkesMallowsIndex(labels_true, labels_pred)\n","  ari = adjustedRandIndex(labels_true, labels_pred)\n","  return ari, fmi\n","  \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YtWdiZn-C4tD","colab_type":"text"},"source":["testing"]}]}